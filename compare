from instream import InStream
from outstream import OutStream
from sketch import Sketch
from bs4 import BeautifulSoup
import requests


k = 5
d = 10000


class PageBroken(Exception):
    def __innit__(self):
        Exception.__init__(self)


class JokesGrabber:
    def __init__(self, website):
        self._website = website

    def readhtml(self, i):
        page = InStream(self._website + str(i))
        return page.readAll()

    def getjokes(self, html):
        end = 0
        trade = 0
        all_jokes = []
        while trade != -1:
            trade = html.find('<section class="body">asdghf', end)
            if trade == -1 and end == 0:
                message = "Error during parsing occurred: check front-end web development of " + self._website
                raise PageBroken(message)
            beg = html.find('>', trade)
            end = html.find('</section>', beg)
            joke = html[beg + 1:end]
            joke = joke.replace('<br />', '')
            joke = joke.replace('&quot;', '')
            joke = joke.replace('            ', '')
            all_jokes += [joke]
        return all_jokes


class NewsGrabber:
    def __init__(self, website):
        self._website = website

    def getnews(self):
        page = requests.get(self._website)
        soup = BeautifulSoup(page.text, 'html.parser')
        text = str(soup.get_text())
        n = text.partition("Еще сюжетыsafhahi")[2]
        if n == "":
            message = "Error during parsing occurred: check front-end web development of " + self._website
            raise PageBroken(message)
        else:
            t = n.partition("Нал.")[0]
            if t == "":
                message = "Error during parsing occurred: check front-end web development of " + self._website
                raise PageBroken(message)
            else:
                return t


class Jokes:
    def __init__(self, filename):
        self._text = InStream(filename)

    def jokes(self):
        t = self._text
        a = []
        while t.hasNextLine():
            str = t.readLine()
            if (not str.isspace()) and (str != ''):
                a += [[str, Sketch(str, k, d)]]
        return a


class News:
    def __init__(self, filename):
        self._text = InStream(filename)

    def news(self):
        t = self._text
        a = []
        while t.hasNextLine():
            str = t.readLine()
            if (not str.isspace()) and (str != ''):
                a += [[str, Sketch(str, k, d)]]
        return a


class Compare:
    def __init__(self, file1, file2):
        n = News(file1)
        j = Jokes(file2)
        self._news = n.news()
        self._jokes = j.jokes()

    def compare(self):
        max = []
        news = self._news
        jokes = self._jokes
        for i in range(4, len(news)):
            m = 0.0
            k = 0
            for j in range(len(jokes)):
                if news[i][1].similarTo(jokes[j][1]) > m:
                    m = news[i][1].similarTo(jokes[j][1])
                    k = j
            max += [k]
        out = OutStream("result.txt")
        for i in range(4, len(news)):
            out.writeln(news[i][0])
            out.writeln(jokes[max[i-4]][0])
            out.writeln("")


def main():
    file1 = "news.txt"
    file2 = "jokes.txt"
    web1 = ""
    web2 = "http://laps.zahav.ru/jokes/list/"
    try:
        news = NewsGrabber(web1)
    except OSError:
        print("No such website (" + web1 + ") or you are disconnected from Internet")
    else:
        out1 = OutStream(file1)
        out1.writeln(news.getnews())
        try:
            grab = JokesGrabber(web2)
            # out2 = OutStream(file2)
            # for page in range(2, 20):
            #    a = grab.getjokes(grab.readhtml(page))
            #    for i in range(len(a) - 1):
            #       out2.writeln(a[i])
            res = Compare(file1, file2)
            res.compare()
        except OSError:
            print("No such website (" + web2 + ") or you are disconnected from Internet")


if __name__ == '__main__':
    main()
